{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/timcsmith/MIS536-Public/master/Data/UniversalBank.csv\"\n",
    "s=requests.get(url).content\n",
    "bank_df=pd.read_csv(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Experience', 'Income', 'Family', 'CCAvg', 'Education',\n",
       "       'Mortgage', 'Personal Loan', 'Securities Account', 'CD Account',\n",
       "       'Online', 'CreditCard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df=bank_df.drop(['ID', 'ZIP Code'],axis=1)\n",
    "bank_df.head()\n",
    "bank_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df['Education'] = bank_df['Education'].astype('category')\n",
    "bank_df = pd.get_dummies(bank_df, prefix_sep='_', drop_first=False)\n",
    "X=band_df.drop(['Personal Loan'],axis=1)\n",
    "y=band_df.iloc[:,6]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.08385594\n",
      "Iteration 2, loss = 0.65032350\n",
      "Iteration 3, loss = 0.60803424\n",
      "Iteration 4, loss = 0.56650923\n",
      "Iteration 5, loss = 0.53082751\n",
      "Iteration 6, loss = 0.45428297\n",
      "Iteration 7, loss = 0.34922108\n",
      "Iteration 8, loss = 0.27548017\n",
      "Iteration 9, loss = 0.19756099\n",
      "Iteration 10, loss = 0.15494463\n",
      "Iteration 11, loss = 0.17223990\n",
      "Iteration 12, loss = 0.16230835\n",
      "Iteration 13, loss = 0.06798807\n",
      "Iteration 14, loss = 0.04825004\n",
      "Iteration 15, loss = 0.23558385\n",
      "Iteration 16, loss = 0.08397793\n",
      "Iteration 17, loss = 0.03313571\n",
      "Iteration 18, loss = 0.04469418\n",
      "Iteration 19, loss = 0.06436815\n",
      "Iteration 20, loss = 0.03636675\n",
      "Iteration 21, loss = 0.02868491\n",
      "Iteration 22, loss = 0.01010003\n",
      "Iteration 23, loss = 0.00612952\n",
      "Iteration 24, loss = 0.02110479\n",
      "Iteration 25, loss = 0.00631741\n",
      "Iteration 26, loss = 0.00148415\n",
      "Iteration 27, loss = 0.00097886\n",
      "Iteration 28, loss = 0.00073633\n",
      "Iteration 29, loss = 0.00057049\n",
      "Iteration 30, loss = 0.00038658\n",
      "Iteration 31, loss = 0.00068694\n",
      "Iteration 32, loss = 0.00022320\n",
      "Iteration 33, loss = 0.00018054\n",
      "Iteration 34, loss = 0.00015658\n",
      "Iteration 35, loss = 0.00015296\n",
      "Iteration 36, loss = 0.00014147\n",
      "Iteration 37, loss = 0.00018560\n",
      "Iteration 38, loss = 0.00014352\n",
      "Iteration 39, loss = 0.00013303\n",
      "Iteration 40, loss = 0.00012754\n",
      "Iteration 41, loss = 0.00012270\n",
      "Iteration 42, loss = 0.00012063\n",
      "Iteration 43, loss = 0.00012569\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Total Time 10.832026720046997\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(500,250,100,40), solver='adam', max_iter=200, verbose=True)\n",
    "model.fit(train_X, train_y)\n",
    "end = time.time()\n",
    "print(\"Total Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1\n",
      " 1 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0\n",
      " 1 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1\n",
      " 0 1 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1\n",
      " 1 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0\n",
      " 0]\n",
      "Total Time 0.034998178482055664\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(model.predict(valid_X))\n",
    "end = time.time()\n",
    "print(\"Total Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time per prediction = 3.0997991561889645e-05\n",
      "Accuracy Score:  1.0\n",
      "Precision Score:  1.0\n",
      "Recall Score:  1.0\n",
      "[[715   0]\n",
      " [  0 285]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "validation_predictions = model.predict(valid_X)\n",
    "end = time.time()\n",
    "print(\"Total Time per prediction =\", (end - start)/len(valid_X))\n",
    "\n",
    "\n",
    "print('Accuracy Score: ', accuracy_score(valid_y, validation_predictions))\n",
    "print('Precision Score: ', precision_score(valid_y, validation_predictions))\n",
    "print('Recall Score: ', recall_score(valid_y, validation_predictions))\n",
    "print(confusion_matrix(validation_predictions,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am not sure if this actually worked as accuracy,precision and recall of 1.0 is unexpected\n",
    "# Evidently confusion matrix is showing that accuracy precision are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.78387872\n",
      "Iteration 2, loss = 0.85447552\n",
      "Iteration 3, loss = 0.64148656\n",
      "Iteration 4, loss = 0.56973635\n",
      "Iteration 5, loss = 0.52665623\n",
      "Iteration 6, loss = 0.49888486\n",
      "Iteration 7, loss = 0.47060186\n",
      "Iteration 8, loss = 0.44163249\n",
      "Iteration 9, loss = 0.41311744\n",
      "Iteration 10, loss = 0.38274062\n",
      "Iteration 11, loss = 0.34586397\n",
      "Iteration 12, loss = 0.31125106\n",
      "Iteration 13, loss = 0.28195135\n",
      "Iteration 14, loss = 0.26202648\n",
      "Iteration 15, loss = 0.23012849\n",
      "Iteration 16, loss = 0.20804698\n",
      "Iteration 17, loss = 0.18736078\n",
      "Iteration 18, loss = 0.17019991\n",
      "Iteration 19, loss = 0.15510511\n",
      "Iteration 20, loss = 0.13732848\n",
      "Iteration 21, loss = 0.12375286\n",
      "Iteration 22, loss = 0.11094421\n",
      "Iteration 23, loss = 0.10164733\n",
      "Iteration 24, loss = 0.09189040\n",
      "Iteration 25, loss = 0.08422954\n",
      "Iteration 26, loss = 0.07671426\n",
      "Iteration 27, loss = 0.07292293\n",
      "Iteration 28, loss = 0.07028558\n",
      "Iteration 29, loss = 0.06163401\n",
      "Iteration 30, loss = 0.05641593\n",
      "Iteration 31, loss = 0.05086859\n",
      "Iteration 32, loss = 0.04705880\n",
      "Iteration 33, loss = 0.04328172\n",
      "Iteration 34, loss = 0.03984148\n",
      "Iteration 35, loss = 0.03691537\n",
      "Iteration 36, loss = 0.03458911\n",
      "Iteration 37, loss = 0.03142541\n",
      "Iteration 38, loss = 0.02928163\n",
      "Iteration 39, loss = 0.02721534\n",
      "Iteration 40, loss = 0.02616886\n",
      "Iteration 41, loss = 0.02347775\n",
      "Iteration 42, loss = 0.02168243\n",
      "Iteration 43, loss = 0.02054966\n",
      "Iteration 44, loss = 0.01937425\n",
      "Iteration 45, loss = 0.01781518\n",
      "Iteration 46, loss = 0.01644990\n",
      "Iteration 47, loss = 0.01519810\n",
      "Iteration 48, loss = 0.01433325\n",
      "Iteration 49, loss = 0.01334654\n",
      "Iteration 50, loss = 0.01255904\n",
      "Iteration 51, loss = 0.01183761\n",
      "Iteration 52, loss = 0.01104890\n",
      "Iteration 53, loss = 0.01043174\n",
      "Iteration 54, loss = 0.00987664\n",
      "Iteration 55, loss = 0.00936471\n",
      "Iteration 56, loss = 0.00899383\n",
      "Iteration 57, loss = 0.00847307\n",
      "Iteration 58, loss = 0.00822683\n",
      "Iteration 59, loss = 0.00765184\n",
      "Iteration 60, loss = 0.00745934\n",
      "Iteration 61, loss = 0.00705636\n",
      "Iteration 62, loss = 0.00683791\n",
      "Iteration 63, loss = 0.00591726\n",
      "Iteration 64, loss = 0.00504389\n",
      "Iteration 65, loss = 0.00449699\n",
      "Iteration 66, loss = 0.00420004\n",
      "Iteration 67, loss = 0.00397357\n",
      "Iteration 68, loss = 0.00377978\n",
      "Iteration 69, loss = 0.00362322\n",
      "Iteration 70, loss = 0.00349880\n",
      "Iteration 71, loss = 0.00334922\n",
      "Iteration 72, loss = 0.00321250\n",
      "Iteration 73, loss = 0.00315037\n",
      "Iteration 74, loss = 0.00302243\n",
      "Iteration 75, loss = 0.00281423\n",
      "Iteration 76, loss = 0.00271111\n",
      "Iteration 77, loss = 0.00262743\n",
      "Iteration 78, loss = 0.00239027\n",
      "Iteration 79, loss = 0.00225778\n",
      "Iteration 80, loss = 0.00211289\n",
      "Iteration 81, loss = 0.00198290\n",
      "Iteration 82, loss = 0.00190197\n",
      "Iteration 83, loss = 0.00176645\n",
      "Iteration 84, loss = 0.00167132\n",
      "Iteration 85, loss = 0.00140757\n",
      "Iteration 86, loss = 0.00111043\n",
      "Iteration 87, loss = 0.00103522\n",
      "Iteration 88, loss = 0.00095996\n",
      "Iteration 89, loss = 0.00090783\n",
      "Iteration 90, loss = 0.00086479\n",
      "Iteration 91, loss = 0.00081496\n",
      "Iteration 92, loss = 0.00077754\n",
      "Iteration 93, loss = 0.00073428\n",
      "Iteration 94, loss = 0.00069868\n",
      "Iteration 95, loss = 0.00066490\n",
      "Iteration 96, loss = 0.00063246\n",
      "Iteration 97, loss = 0.00060699\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Total Time 2.5610265731811523\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100), solver='adam', max_iter=100, verbose=True)\n",
    "model.fit(train_X, train_y)\n",
    "end = time.time()\n",
    "print(\"Total Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time per prediction = 5.9967041015625e-06\n",
      "Accuracy Score:  1.0\n",
      "Precision Score:  1.0\n",
      "Recall Score:  1.0\n",
      "[[715   0]\n",
      " [  0 285]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "validation_predictions = model.predict(valid_X)\n",
    "end = time.time()\n",
    "print(\"Total Time per prediction =\", (end - start)/len(valid_X))\n",
    "\n",
    "\n",
    "print('Accuracy Score: ', accuracy_score(valid_y, validation_predictions))\n",
    "print('Precision Score: ', precision_score(valid_y, validation_predictions))\n",
    "print('Recall Score: ', recall_score(valid_y, validation_predictions))\n",
    "print(confusion_matrix(validation_predictions,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.79612222\n",
      "Iteration 2, loss = 0.80797544\n",
      "Iteration 3, loss = 0.62296179\n",
      "Iteration 4, loss = 0.61020097\n",
      "Iteration 5, loss = 0.61004171\n",
      "Iteration 6, loss = 0.60991697\n",
      "Iteration 7, loss = 0.60978392\n",
      "Iteration 8, loss = 0.60963165\n",
      "Iteration 9, loss = 0.60949624\n",
      "Iteration 10, loss = 0.60937300\n",
      "Iteration 11, loss = 0.60922375\n",
      "Iteration 12, loss = 0.60910323\n",
      "Iteration 13, loss = 0.60897489\n",
      "Iteration 14, loss = 0.60886363\n",
      "Iteration 15, loss = 0.60876457\n",
      "Iteration 16, loss = 0.60865709\n",
      "Iteration 17, loss = 0.60854925\n",
      "Iteration 18, loss = 0.60847690\n",
      "Iteration 19, loss = 0.60838291\n",
      "Iteration 20, loss = 0.60830378\n",
      "Iteration 21, loss = 0.60823834\n",
      "Iteration 22, loss = 0.60817682\n",
      "Iteration 23, loss = 0.60812296\n",
      "Iteration 24, loss = 0.60805954\n",
      "Iteration 25, loss = 0.60801580\n",
      "Iteration 26, loss = 0.60797079\n",
      "Iteration 27, loss = 0.60793746\n",
      "Iteration 28, loss = 0.60790127\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Total Time 0.9039962291717529\n",
      "Wall time: 904 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(10,15,20,5,3), solver='adam', max_iter=200, verbose=True)\n",
    "model.fit(train_X, train_y)\n",
    "end = time.time()\n",
    "print(\"Total Time\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time per prediction = 4.997014999389648e-06\n",
      "Accuracy Score:  0.715\n",
      "Precision Score:  0.0\n",
      "Recall Score:  0.0\n",
      "[[715 285]\n",
      " [  0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "validation_predictions = model.predict(valid_X)\n",
    "end = time.time()\n",
    "print(\"Total Time per prediction =\", (end - start)/len(valid_X))\n",
    "\n",
    "\n",
    "print('Accuracy Score: ', accuracy_score(valid_y, validation_predictions))\n",
    "print('Precision Score: ', precision_score(valid_y, validation_predictions))\n",
    "print('Recall Score: ', recall_score(valid_y, validation_predictions))\n",
    "print(confusion_matrix(validation_predictions,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at all three combinations it is evident that having more neurons in this case matters more than having \n",
    "# more layers. Last one specifically was example of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First combination of 4 hidden layers \n",
    "#Total Time per prediction = 3.0997991561889645e-05\n",
    "#Accuracy Score:  1.0\n",
    "#Precision Score:  1.0\n",
    "#Recall Score:  1.0\n",
    "#[[715   0]\n",
    "# [  0 285]]\n",
    "\n",
    "#Second combo with only one hidden layer with 100 neurons\n",
    "#Total Time per prediction = 5.9967041015625e-06\n",
    "#Accuracy Score:  1.0\n",
    "#Precision Score:  1.0\n",
    "#Recall Score:  1.0\n",
    "#[[715   0]\n",
    "# [  0 285]]\n",
    "\n",
    "# third combo with five hidden layers\n",
    "#Total Time per prediction = 4.997014999389648e-06\n",
    "#Accuracy Score:  0.715\n",
    "#Precision Score:  0.0\n",
    "#Recall Score:  0.0\n",
    "#[[715 285]\n",
    "# [  0   0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5000 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1316 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2448 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3908 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5688 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7796 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 10224 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 12980 tasks      | elapsed:  4.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'n_neighbors': 6, 'p': 1, 'weights': 'distance'}\n",
      "Total Time = 344.68347358703613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 14993 out of 15000 | elapsed:  5.7min remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 15000 out of 15000 | elapsed:  5.7min finished\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "neigh=np.linspace(1,50,50)\n",
    "neigh=list(neigh)\n",
    "neigh=[int(i) for i in neigh]\n",
    "p=np.linspace(1,10,10)\n",
    "p=list(neigh)\n",
    "p=[int(i) for i in neigh]\n",
    "param_grid={'n_neighbors':neigh,\n",
    "           'p':p,\n",
    "            'weights':['uniform', 'distance']}\n",
    "gridSearch = GridSearchCV(estimator = KNeighborsClassifier(), param_grid=param_grid, cv = 3, verbose=2,  n_jobs = -1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "bestGridModel = gridSearch.best_estimator_\n",
    "print('Best parameters found: ', gridSearch.best_params_)\n",
    "end = time.time()\n",
    "print(\"Total Time =\", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time per prediction = 1.0998010635375976e-05\n",
      "0.876\n",
      "0.867579908675799\n",
      "0.6666666666666666\n",
      "[[686  95]\n",
      " [ 29 190]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "validation_predictions = bestGridModel.predict(valid_X)\n",
    "end = time.time()\n",
    "print(\"Total Time per prediction =\", (end - start)/len(valid_X))\n",
    "print(accuracy_score(valid_y, validation_predictions))\n",
    "print(precision_score(valid_y, validation_predictions))\n",
    "print(recall_score(valid_y, validation_predictions))\n",
    "print(confusion_matrix(validation_predictions,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kneghbours classifier did not perform as well as MLP classifier\n",
    "# Although it did well enough when looking at correct predictions it has made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare time taken\n",
    "#training time:\n",
    "# Total Time 10.832026720046997 secs ; 4 hidden layers with lot of neurons\n",
    "#Total Time 2.5610265731811523 sec  ; 1 hidden layer\n",
    "# Total Time 0.9039962291717529 sec  ; 5 hidden layers with few less neurons\n",
    "# total time for KNN : 344.68347358703613 sec\n",
    "# KNN took lot longer time than neural network and one reason with that is gridsearch parameters.\n",
    "# KNN had 1000 combinations so per combination it would be 34.4 seconds\n",
    "# Let's try only one combination and see how long it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time= 0.016998291015625\n",
      "0.876\n",
      "0.867579908675799\n",
      "0.6666666666666666\n",
      "[[686  95]\n",
      " [ 29 190]]\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "clf=KNeighborsClassifier(n_neighbors=6,p=1,weights='distance')\n",
    "clf.fit(train_X, train_y)\n",
    "end = time.time()\n",
    "print(\"Total Time=\", (end - start))\n",
    "print(accuracy_score(valid_y, validation_predictions))\n",
    "print(precision_score(valid_y, validation_predictions))\n",
    "print(recall_score(valid_y, validation_predictions))\n",
    "print(confusion_matrix(validation_predictions,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time taken is significantly lower now\n",
    "# Although gridsearch is necessary for this KNN as we don't know prior what combination is perfect.\n",
    "# So MLP is better for time consumed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare time per validation\n",
    "# Total Time per prediction = 1.0998010635375976e-05          ;KNN\n",
    "# maximum Total Time per prediction = 3.0997991561889645e-05  ;MLP\n",
    "# This time is very much comparable and one can't say for sure which one will take less time\n",
    "# This is because every run I made and repeated gave me different time\n",
    "# one example is illustrated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time per prediction = 8.03232192993164e-06\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "validation_predictions = bestGridModel.predict(valid_X)\n",
    "end = time.time()\n",
    "print(\"Total Time per prediction =\", (end - start)/len(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So all things considered MLP is much better for time consumptions and accuracy is very high as well\n",
    "# I would recommend this model \n",
    "# Although I read some amount on tensorflow models which are better than scikitlearn if model is available \n",
    "# And tensorflow has GPU capabilities which will improve calculation time and ne can train huge data and \n",
    "# can use more neurons and layers without losing lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
